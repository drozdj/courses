# Scott Aaronson, 2022, ‚ÄúReform AI Alignment‚Äù, Shtetl-Optimized blog. Also, Boaz Barak and Ben Edelman, 2022, ‚ÄúAI will change the world, but won‚Äôt take it over by playing ‚Äò3- dimensional chess‚Äô‚Äù

Updated: 31.07.24

Status: Draft

---
> "We believe that this is uncontroversial - for example, it‚Äôs not far-fetched to claim that AI would make much better chess players than kindergarten teachers."
* it is not immediately obvious to me that this is the case.
    * consider, 

> "An AI engineer will be much more useful than an AI CEO (see also Table 2)"
* im struggling hard to conceive this as true. the point the author tries to make is that of AIs being effective at short-term tasks (with what i understand to be, tight feedback loops. chess, image recognition, etc). and long-term tasks, running a company / teaching. it doesn't quite sink in how the long-term tasks are not just a agglomeration of various *different* short-term tasks which can be many narrow-AIs with say, a 'master' AI that forms the right decision. Of course, having a human do this would be a more efficient idea, but what about tasks such as crypto mining which humans may not want as its boring?

> "Even if a long-term AI system is built, it will likely not have a significant advantage over humans assisted with short-term AIs."
* the author tackles my take on ai 'masters'.
* im unsure that this is the above is true. consider that "humans" in the context presented actually were of median intelligence, in several 

> Arguably, the fact humans are far better than chimpanzees at culturally transmitting knowledge is more significant than the gap in intelligence between individuals of the two species.
* what on earth. my mind ü§Ø
    * i struggle to see how if chimpanzees were able to "culturally transmit knowledge" well, how that would play out. and somehow i do struggle to visualize that it would be very different.
    * what does it mean to "culturally transmit knowledge"?
        * how about those that spent entire lives in isolation yet have produced amazing feats of work? (by societal standards) 

> "The brilliance of individuals like Newton may have been crucial for speeding up the Scientific Revolution, but there have been brilliant individuals for millennia. The crucial difference between Newton and Archimedes is not that Newton was smarter, but rather that he lived at a later time and thus was able to stand on the shoulders of more giants. As another example, a collection of humans, aided by Internet-connected computers, can do much better at pretty much any intelligence feat (including but not limited to IQ exams) than any single human."
* what a great point!


> "Also, the only way to accrue the benefits of the strategy would be to continue pursuing it in the long term. Hence users would have to trust the AI and follow its recommendations blindly. For example, think of the case in Chess where an AI figures out that the best move is to sacrifice the queen because for any one of the possible opponent‚Äôs moves, there is a countermove, and so on and so forth. The only explanation for why this strategy is a good one may consist of an exponentially big game tree up to a certain depth."
* > "There is an alternative viewpoint, which is that an AI CEO would basically be equivalent to a human CEO but with superhuman ‚Äúintuition‚Äù or ‚Äúgut feeling‚Äù that they cannot explain but somehow leads to decisions that yield enormous benefits in the long term. While this viewpoint cannot be ruled out, there is no evidence in current deep learning successes to support it."
    * it is important to notice that we do not know when that *wild* decision (such as the queen sacrifice) will converge in the real world, in the space of a classical chess game it can be anywhere <120minutes. but in the real world, it could be decades if not centuries, or millennia... and what happens if it gathers valuble data which *changes* its worldview? then how does that queen sacrifise play out? (because we know it didn't simply brute-force search all the possiblities, *ever*...?)

> "Indeed, by far the most exciting advances for deep learning have not been through reinforcement learning, but rather through techniques such as supervised and unsupervised learning. (With the major exception being games like Chess and Go, though even there, given the success of non-RL engines such as Stockfish versions 12 and later, it is not clear RL is needed.)" 
1* üòÆ
> "The real world (unlike the game of chess or even poker), involves a significant amount of unpredictability and chaos, which makes highly elaborate strategies depending on complex branching trees of moves and counter-moves far less useful."
* i think what the author is getting at in this entire paper is something akin to [The Bitter Lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html). however, (ironically) the author of Bitter Lesson is Richard Sutton, a pioneer of RL even writing a textbook about it!
    * they do both believe that computation is the core idea. Boaz Barak believes that **brute-force** is what AI is best at and it should stay this way (supervised, unsupervised). and that abstracting beyond that in non-narrow environments where goals can be misaligned (RL) should be dropped altogethe, he makes the claim that all the notable accomplishments in RL (AlphaZero Chess, Go) could have very well been done in supervised learning narrow environments (Stockfish Version >=12 ).

---
## Key points
* short-term AI
* long-term AI
* 

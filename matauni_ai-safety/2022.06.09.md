# Norbert Wiener, 1960, “Some moral and technical consequences of automation”, Science.

--- 

*  >To be effective in warding off disastrous consequences, our understanding of our man-made machines should in general develop pari passu with the performance of the machine.   
    * >By the very  slowness of our human actions, our  effective control of our machines may  be nullified. By the time we are able  to react to information conveyed by  our senses and stop the car we are  driving, it may already have run head  on into a wall.
        * 

* >To avoid a disastrous consequence, it is  not enough that some action on our part should be sufficient to change the course of the machine, because it is quite possible that we lack information on which to base consideration of such  an action. 

* >when a machine constructed  by us is capable of operating on its in-  coming data at a pace which we can-  not keep, we may not know, until too  late, when to turn it off.

* what is the sorcerer's apprentice?


* some review questions
    * what is the man in the streets opinion?
        * .
        * how should it be treated according to Wiener?
            * .

---
## Key Points

### 06.07.24 -- whole paper read
* ability to see the potential dangers of developing a machine to complete tasks of which we do not fully comprehend internals off
* toy environments where theory has been well established (checkers) & can mostly be solved using game-theory. vs real-world games (war & business), with no *established* theory behind it.
* complete subservience & complete intelligence is on a spectrum
    * how can we expect a machine to do exactly as we say but at the same time want it to be smarter than us..?
        * this is a contradiction. ex. how many times have we seen a awefully intelligent greek philosopher rise from beneath their roman masters foot.

# Tobias Wängberg et al., 2017, “A game-theoretic analysis of the of the off-switch game”, AGI 2017. 

---

* 1. look for arguements & critiques of the paper
    * couldn't find any on the web. but perplexity.ai gave a summary


>This utility function may either be preprogrammed by the designers, or learnt (Dewey, 2011). 
* >"... or learnt" 
    * if it had not had a specific *terminal goal*, then what really is it?
        * the sum of its sub-parts
    * 

>A key dynamic in the uncertainty approach is when the agent should defer a decision to a human, and when not.  
* >"... and when not."
    * not being *corrigible* to the wrong-intentioned human 
        * this tackles my earlier uncertainty with the question 'what if the human's utility function is not good?'
            * what are some solutions for this?
                * having a 'voting' or an 'averaging' system, in which not one, but many are involved in the the agents utility function.

> Humans may make a wrong or irrational decision due to inconsistent preferences (Allais, 1953), or because of inability to sufficiently process available data fast enough (as in milli-second stock trading)
* > "... or because of inability to sufficiently process available data fast enough (as in milli-second stock trading)"
    * this communication barrier is one of importance, consider that an agent is operating on many many more computations than we can possibly cope with. what does it then do when it awaits the humans response? does it skip over that decision and continue? what hope do we have that it will return to it & not just discard of it (because its no longer in the present -- therefor no real effect on utility function)
        * at the beginning, i am sure that the agent's will **not** have much certainty, in these cases? does it just delegate everything to the human?
        * also, real-world decision making entails so many states which appear as long-tail (but are not actually), because the tail is it all!

> but emphasise that the off-switch game models any situation where an agent has the option of deferring a decision to a human. 
* "off-switch" is not defined in the way in which we all expected (that when a human tells the agent to terminate, it does). <br> but rather it is defined **by wether it prioritizes a humans decision making over its own**


* this paper would benefit from another glance through in the future,
    * i wasn't able to capture from the point where the Nature was introducted fro Harsanyi transformations as very technical and dense

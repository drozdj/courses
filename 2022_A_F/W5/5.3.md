# Supervising strong learners by amplifying weak experts (Christiano et al., 2018)

--- 

* paper summary.
    * learning is a complex task. authors approach via a training strategy that breaks down a difficult problem into many *easier* subproblems. 

* >We propose Iterated Amplification, an alternative training strategy which progressively builds up a training signal for difficult problems by combining solutions to easier subproblems.
    * kinda like dynamic programming?

* uses "no external reward function"

* this paper doesn't make much sense to me.
    * why would you ever use several dumber AIs answers to assist you (a smart AI) on how to do a task?
        * wouldn't  

* >Unfortunately, most useful tasks donâ€™t have an algorithmic training signal. 
    * lets consider a case where this is true, but firstly lets define useful task.
        * the tasks that are mentioned are ones in which a human is able to *nudge* the agent into the correct direction
        by settings a *terminal reward* (gather more points than enemy ingame), and *reward-shaping* to lead towards it.        
        * the concern is that for most applications that are real-world. there isn't a *terminal reward* that the agent can
        persue. ex. being a personal assistant to a CEO. sure, there are *priorities* that should be set, but all tasks that 
        are given to it *have* to be completed.
        *


--- 
# Key Points
* Iterated Amplification
* Expert Iteration
* 

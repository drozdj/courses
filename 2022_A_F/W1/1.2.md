# AGI safety from first principles (Ngo, 2020) (only sections 1 and 2)

---
### Notes
>An example of the generalisation-based approach can be found in large language models like GPT-2 and GPT-3.
* i don't think that this is a *generalisation-based* approach, rather it seems to be a *task-specific*.
the reason i say that is because GPT {1,2,3} where created to predict the next word in a text corpus, and thats it.
they are unable to apply their models to any other domain than that very specific application. <br>
a generalisation approach would be if it were now able to be given only the ending of a sentance and correctly filled in
the first half.
> and then achieved state of the art results on many other language tasks
* maybe this is were the generalisation comes in? 


>"I think of task-based and generalisation-based as parts of a spectrum rather than a binary classification, particularly because the way we choose how to divide up tasks can be quite arbitrary." 
* //TODO: provide a example for when something like this can occur. where a community is split into two beliefs over a hard-to-define thing.

--- 
### Recall 0 | 02.07.24 | 30M <-> 45M

* what is this paper about?
    * //TODO:

* how do we define intelligence?
    * //TODO:

#### Argue against these points after recall finished.
* > "The task-based approach is analogous to how humans harnessed electricity: while electricity is a powerful and general technology, we still need to design specific ways to apply it to each task." 
    * //TODO:

* what is meta-learning and how may AI's use it?
    * //TODO:

* how were we {below} 'trained'
    1. as a species -- what skills?
        * //TODO:
    2. as individuals -- what fine-tuning?
        * //TODO:


--- 
### Key Points
* "second species" argument
* tasked-based approach
* generalisation-based approach
* meta-learning
* ai duplication
* artificial general intelligence (AGI)
* collective AGI
* recursive improvement
* self-modification
